{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 7280730,
          "sourceType": "datasetVersion",
          "datasetId": 4221454
        }
      ],
      "dockerImageVersionId": 30627,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0b493b465eb54645b25aec59d4d25b04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eedd59e2bba6422f8adb100c808a79ba",
              "IPY_MODEL_53e1910f461b4644ae25936e4131a54d",
              "IPY_MODEL_490b67bb0fcd44efa6b481694fe80129"
            ],
            "layout": "IPY_MODEL_b98c2132cc72489384a90d1908037b84"
          }
        },
        "eedd59e2bba6422f8adb100c808a79ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_670b0f3f82484dae9cc106ebff0816fd",
            "placeholder": "​",
            "style": "IPY_MODEL_826a03da86c94e619df0c59bbbfe33b9",
            "value": "Map: 100%"
          }
        },
        "53e1910f461b4644ae25936e4131a54d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_275e99bb7e344a2988d4aa7c572b61c5",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9d62c214724b41688a970ca7f5f220be",
            "value": 1000
          }
        },
        "490b67bb0fcd44efa6b481694fe80129": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4fd33323970644998da0547c83b15987",
            "placeholder": "​",
            "style": "IPY_MODEL_73eab8393ea640e8a50914a027247663",
            "value": " 1000/1000 [00:04&lt;00:00, 234.35 examples/s]"
          }
        },
        "b98c2132cc72489384a90d1908037b84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "670b0f3f82484dae9cc106ebff0816fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "826a03da86c94e619df0c59bbbfe33b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "275e99bb7e344a2988d4aa7c572b61c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d62c214724b41688a970ca7f5f220be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4fd33323970644998da0547c83b15987": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73eab8393ea640e8a50914a027247663": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe701bc358534709ac4ac88c4d93b093": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b98969a43a04417399096d1888aeaffd",
              "IPY_MODEL_a73f22793df44d6cacd2d13815a84457",
              "IPY_MODEL_75a9e1b8adae4911b8070d363a017f96"
            ],
            "layout": "IPY_MODEL_bd01fca21cfd4021aac7d0f18290563e"
          }
        },
        "b98969a43a04417399096d1888aeaffd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b53f83865b04b4992ea6aefbd6ee02c",
            "placeholder": "​",
            "style": "IPY_MODEL_c8d3c0d50864430bab68ecf5c600d58a",
            "value": "Map: 100%"
          }
        },
        "a73f22793df44d6cacd2d13815a84457": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac0a17cdfe904c57ac5cd0298ed065cf",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_330a9a8e32fa4bdbaf00b0906dcd42ab",
            "value": 100
          }
        },
        "75a9e1b8adae4911b8070d363a017f96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7475e4592ff449bb61569be3000e549",
            "placeholder": "​",
            "style": "IPY_MODEL_dbe60b2837b34e0ba6029ba987ef98c4",
            "value": " 100/100 [00:00&lt;00:00, 122.85 examples/s]"
          }
        },
        "bd01fca21cfd4021aac7d0f18290563e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b53f83865b04b4992ea6aefbd6ee02c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8d3c0d50864430bab68ecf5c600d58a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ac0a17cdfe904c57ac5cd0298ed065cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "330a9a8e32fa4bdbaf00b0906dcd42ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d7475e4592ff449bb61569be3000e549": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbe60b2837b34e0ba6029ba987ef98c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **FINE TUNING LLM FOR TEXT SUMMARIZATION**\n",
        "### DATASET - [CNN Dailymail Dataset](https://huggingface.co/datasets/cnn_dailymail).\n",
        "- The **CNN / DailyMail Dataset** is an English-language dataset containing just over 300k unique news articles as written by journalists at CNN and the Daily Mail.\n",
        "#### Data Fields\n",
        "- **id**: a string containing the heximal formated SHA1 hash of the url where the story was retrieved from\n",
        "- **article**: a string containing the body of the news article\n",
        "- **highlights**: a string containing the highlight of the article as written by the article author\n",
        "<br>\n",
        "\n"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "id": "qpDKtqju3QHj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U bitsandbytes\n",
        "!pip install transformers==4.31\n",
        "# !pip install -q -U git+https://github.com/huggingface/peft.git\n",
        "!pip install peft==0.9.0\n",
        "!pip install -q datasets\n",
        "!pip install -qqq trl==0.7.1"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-27T16:31:51.695170Z",
          "iopub.execute_input": "2023-12-27T16:31:51.695556Z",
          "iopub.status.idle": "2023-12-27T16:33:18.569941Z",
          "shell.execute_reply.started": "2023-12-27T16:31:51.695524Z",
          "shell.execute_reply": "2023-12-27T16:33:18.568680Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDW-Qhhs3QHk",
        "outputId": "b534eeff-4602-4fca-9df2-7671ee9ec55c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers==4.31\n",
            "  Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.31) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31) (0.23.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.31) (2.31.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.31)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.31) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.31) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.31) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.31) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.31) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.31) (2024.6.2)\n",
            "Installing collected packages: tokenizers, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.19.1\n",
            "    Uninstalling tokenizers-0.19.1:\n",
            "      Successfully uninstalled tokenizers-0.19.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.41.2\n",
            "    Uninstalling transformers-4.41.2:\n",
            "      Successfully uninstalled transformers-4.41.2\n",
            "Successfully installed tokenizers-0.13.3 transformers-4.31.0\n",
            "Collecting peft==0.9.0\n",
            "  Downloading peft-0.9.0-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.9/190.9 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft==0.9.0) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.9.0) (24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft==0.9.0) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft==0.9.0) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.9.0) (2.3.0+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft==0.9.0) (4.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft==0.9.0) (4.66.4)\n",
            "Collecting accelerate>=0.21.0 (from peft==0.9.0)\n",
            "  Downloading accelerate-0.31.0-py3-none-any.whl (309 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.4/309.4 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft==0.9.0) (0.4.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.9.0) (0.23.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft==0.9.0) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft==0.9.0) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft==0.9.0) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft==0.9.0) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.9.0) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.9.0) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.9.0) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.9.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.9.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.9.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.9.0) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.9.0) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.9.0) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.9.0) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.9.0) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.9.0) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.9.0) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.9.0) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.9.0) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->peft==0.9.0) (12.5.82)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft==0.9.0) (2024.5.15)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers->peft==0.9.0) (0.13.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft==0.9.0) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft==0.9.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft==0.9.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft==0.9.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft==0.9.0) (2024.6.2)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft==0.9.0) (1.3.0)\n",
            "Installing collected packages: accelerate, peft\n",
            "Successfully installed accelerate-0.31.0 peft-0.9.0\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 16.1.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 16.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.0/118.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pyarrow==14.0.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "4vdUBEYeFlxV",
        "outputId": "d748725e-6bd3-40bc-a024-1fa589b358a5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyarrow==14.0.2\n",
            "  Downloading pyarrow-14.0.2-cp310-cp310-manylinux_2_28_x86_64.whl (38.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.0/38.0 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.10/dist-packages (from pyarrow==14.0.2) (1.25.2)\n",
            "Installing collected packages: pyarrow\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 16.1.0\n",
            "    Uninstalling pyarrow-16.1.0:\n",
            "      Successfully uninstalled pyarrow-16.1.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datasets 2.20.0 requires pyarrow>=15.0.0, but you have pyarrow 14.0.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pyarrow-14.0.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pyarrow"
                ]
              },
              "id": "3f8c1401ba1844cd9d595b0e43809dad"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from datasets import Dataset, load_dataset\n",
        "from datasets import load_dataset, load_metric\n",
        "from transformers import pipeline, set_seed\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-27T16:34:37.978097Z",
          "iopub.execute_input": "2023-12-27T16:34:37.978819Z",
          "iopub.status.idle": "2023-12-27T16:34:37.985202Z",
          "shell.execute_reply.started": "2023-12-27T16:34:37.978782Z",
          "shell.execute_reply": "2023-12-27T16:34:37.984116Z"
        },
        "trusted": true,
        "id": "k6GA82Ct3QHl"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **THE CNN DAILY MAIL DATASET**"
      ],
      "metadata": {
        "id": "eIZsKKTv3QHl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "huggingface_dataset_name = \"cnn_dailymail\"\n",
        "\n",
        "dataset = load_dataset(huggingface_dataset_name, \"3.0.0\")\n",
        "dataset"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-27T16:34:41.224562Z",
          "iopub.execute_input": "2023-12-27T16:34:41.225550Z",
          "iopub.status.idle": "2023-12-27T16:38:00.499042Z",
          "shell.execute_reply.started": "2023-12-27T16:34:41.225512Z",
          "shell.execute_reply": "2023-12-27T16:38:00.497647Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6CCOkZt3QHl",
        "outputId": "75672572-0986-40f4-bea8-31bacb2949d8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['article', 'highlights', 'id'],\n",
              "        num_rows: 287113\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['article', 'highlights', 'id'],\n",
              "        num_rows: 13368\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['article', 'highlights', 'id'],\n",
              "        num_rows: 11490\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LOOKING OUT FOR A SAMPLE"
      ],
      "metadata": {
        "id": "ZjCk-fvn3QHl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample = dataset[\"train\"][1]\n",
        "print(f\"\"\"Article (excerpt of 500 characters, total length: {len(sample[\"article\"])}):\"\"\")\n",
        "print(sample[\"article\"][:500])\n",
        "print(f'\\nSummary (length: {len(sample[\"highlights\"])}):')\n",
        "print(sample[\"highlights\"])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-27T16:38:00.501168Z",
          "iopub.execute_input": "2023-12-27T16:38:00.501820Z",
          "iopub.status.idle": "2023-12-27T16:38:00.510261Z",
          "shell.execute_reply.started": "2023-12-27T16:38:00.501782Z",
          "shell.execute_reply": "2023-12-27T16:38:00.509295Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3EwvBV7n3QHl",
        "outputId": "bbc5260b-4df2-4d97-c026-5341862d80da"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Article (excerpt of 500 characters, total length: 4051):\n",
            "Editor's note: In our Behind the Scenes series, CNN correspondents share their experiences in covering news and analyze the stories behind the events. Here, Soledad O'Brien takes users inside a jail where many of the inmates are mentally ill. An inmate housed on the \"forgotten floor,\" where many mentally ill inmates are housed in Miami before trial. MIAMI, Florida (CNN) -- The ninth floor of the Miami-Dade pretrial detention facility is dubbed the \"forgotten floor.\" Here, inmates with the most s\n",
            "\n",
            "Summary (length: 281):\n",
            "Mentally ill inmates in Miami are housed on the \"forgotten floor\"\n",
            "Judge Steven Leifman says most are there as a result of \"avoidable felonies\"\n",
            "While CNN tours facility, patient shouts: \"I am the son of the president\"\n",
            "Leifman says the system is unjust and he's fighting for change .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PRE PROCESSING FUNCTIONS"
      ],
      "metadata": {
        "id": "n_wmz0u13QHl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Converting the `article text` and `summary` to a `prompt`:**\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "    Summarize the following conversation.\n",
        "    \n",
        "    ### Input:\n",
        "    (CNN) -- Usain Bolt rounded off the world championships Sunday by claiming his third\n",
        "    gold in Moscow as he anchored Jamaica to\n",
        "    victory in the men's 4x100m relay. The fastest man in the world charged clear of United\n",
        "    States rival Justin Gatlin as the Jamaican\n",
        "    quartet of Nesta Carter, Kemar Bailey-Cole, Nickel Ashmeade and Bolt won in 37.36\n",
        "    seconds. The U.S finished second in 37.56 seconds\n",
        "    with Canada taking the bronze after Britain were disqualified for a faulty handover.\n",
        "    The 26-year-old Bolt has n......\n",
        "    \n",
        "\n",
        "    ### Summary:\n",
        "\n",
        "    Usain Bolt wins third gold of world championship .\n",
        "    Anchors Jamaica to 4x100m relay victory .\n",
        "    Eighth gold at the championships for Bolt .\n",
        "    Jamaica double up in women's 4x100m relay .\n",
        "```"
      ],
      "metadata": {
        "id": "NUnq-KOe3QHl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def format_instruction(dialogue: str, summary: str):\n",
        "    return f\"\"\"### Instruction:\n",
        "Summarize the following conversation.\n",
        "\n",
        "### Input:\n",
        "{dialogue.strip()}\n",
        "\n",
        "### Summary:\n",
        "{summary}\n",
        "\"\"\".strip()\n",
        "\n",
        "def generate_instruction_dataset(data_point):\n",
        "\n",
        "    return {\n",
        "        \"article\": data_point[\"article\"],\n",
        "        \"highlights\": data_point[\"highlights\"],\n",
        "        \"text\": format_instruction(data_point[\"article\"],data_point[\"highlights\"])\n",
        "    }\n",
        "\n",
        "def process_dataset(data: Dataset):\n",
        "    return (\n",
        "        data.shuffle(seed=42)\n",
        "        .map(generate_instruction_dataset).remove_columns(['id'])\n",
        "    )"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-27T16:38:00.511450Z",
          "iopub.execute_input": "2023-12-27T16:38:00.511767Z",
          "iopub.status.idle": "2023-12-27T16:38:00.790081Z",
          "shell.execute_reply.started": "2023-12-27T16:38:00.511741Z",
          "shell.execute_reply": "2023-12-27T16:38:00.789117Z"
        },
        "trusted": true,
        "id": "MrLi6q9e3QHl"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## APPLYING PREPROCESSING ON WHOLE DATASET\n",
        "dataset[\"train\"] = process_dataset(dataset[\"train\"])\n",
        "dataset[\"test\"] = process_dataset(dataset[\"validation\"])\n",
        "dataset[\"validation\"] = process_dataset(dataset[\"validation\"])\n",
        "\n",
        "# Select 1000 rows from the training split\n",
        "train_data = dataset['train'].shuffle(seed=42).select([i for i in range(1000)])\n",
        "\n",
        "# Select 100 rows from the test and validation splits\n",
        "test_data = dataset['test'].shuffle(seed=42).select([i for i in range(100)])\n",
        "validation_data = dataset['validation'].shuffle(seed=42).select([i for i in range(100)])\n",
        "\n",
        "train_data,test_data,validation_data"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-27T16:38:00.792913Z",
          "iopub.execute_input": "2023-12-27T16:38:00.793330Z",
          "iopub.status.idle": "2023-12-27T16:38:52.679132Z",
          "shell.execute_reply.started": "2023-12-27T16:38:00.793294Z",
          "shell.execute_reply": "2023-12-27T16:38:52.678100Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Za9ZB6Dy3QHl",
        "outputId": "6cb0bcb2-1c22-451c-8c4c-e0ceb56aec07"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Dataset({\n",
              "     features: ['article', 'highlights', 'text'],\n",
              "     num_rows: 1000\n",
              " }),\n",
              " Dataset({\n",
              "     features: ['article', 'highlights', 'text'],\n",
              "     num_rows: 100\n",
              " }),\n",
              " Dataset({\n",
              "     features: ['article', 'highlights', 'text'],\n",
              "     num_rows: 100\n",
              " }))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **THE LLAMA-2 7B MODEL**"
      ],
      "metadata": {
        "id": "PJnPhmg_3QHl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "export CUDA_LAUNCH_BLOCKING=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "d6HFFDDbvc44",
        "outputId": "61d2856a-437f-4ae6-e86c-14f249689a9b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-17-56efdc3ca8f4>, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-17-56efdc3ca8f4>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    export CUDA_LAUNCH_BLOCKING=1\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "\n",
        "# Check if GPU is available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model_id = \"openai-community/gpt2\"\n",
        "\n",
        "# Configuration for loading the model with 4-bit quantization\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.float32,\n",
        "    # load_in_8bit_fp32_cpu_offload=True  # Enable CPU offloading for 32-bit precision\n",
        ")\n",
        "\n",
        "# Load the model with the specified quantization configuration\n",
        "try:\n",
        "    model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config)\n",
        "except ValueError as e:\n",
        "    print(f\"ValueError: {e}\")\n",
        "    print(\"Attempting to load the model without quantization configuration as a fallback.\")\n",
        "    model = AutoModelForCausalLM.from_pretrained(model_id)\n",
        "\n",
        "# Move the model to GPU if available\n",
        "if device.type == 'cuda':\n",
        "    model.cuda()\n",
        "\n",
        "# Load the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"right\"\n",
        "\n",
        "print(\"Model and tokenizer loaded successfully!\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-27T16:38:52.680311Z",
          "iopub.execute_input": "2023-12-27T16:38:52.680652Z",
          "iopub.status.idle": "2023-12-27T16:41:35.687771Z",
          "shell.execute_reply.started": "2023-12-27T16:38:52.680620Z",
          "shell.execute_reply": "2023-12-27T16:41:35.686649Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gUhd6wa3QHm",
        "outputId": "fa51053e-95ba-4263-b849-7bbc2ea2d0a1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of GPT2LMHeadModel were not initialized from the model checkpoint at openai-community/gpt2 and are newly initialized: ['lm_head.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model and tokenizer loaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqgS33sNG8GT",
        "outputId": "96755868-274a-44f2-abd2-a03cc0a46f1b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ZERO-SHOT INFERENCE WITH LLAMA-2 7B"
      ],
      "metadata": {
        "id": "DFtpWbFZ3QHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index = 2\n",
        "\n",
        "dialogue = test_data['article'][index]\n",
        "summary = test_data['highlights'][index]\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Summarize the following conversation.\n",
        "\n",
        "### Input:\n",
        "{dialogue}\n",
        "\n",
        "### Summary:\n",
        "\"\"\"\n",
        "\n",
        "inputs = tokenizer(prompt, return_tensors='pt')\n",
        "output = tokenizer.decode(\n",
        "    model.generate(\n",
        "        inputs[\"input_ids\"],\n",
        "        max_new_tokens=100,\n",
        "    )[0],\n",
        "    skip_special_tokens=True\n",
        ")\n",
        "\n",
        "dash_line = '-'.join('' for x in range(100))\n",
        "print(dash_line)\n",
        "print(f'INPUT PROMPT:\\n{prompt}')\n",
        "print(dash_line)\n",
        "print(f'BASELINE HUMAN SUMMARY:\\n{summary}\\n')\n",
        "print(dash_line)\n",
        "print(f'MODEL GENERATION - ZERO SHOT:\\n{output}')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-27T16:41:35.689229Z",
          "iopub.execute_input": "2023-12-27T16:41:35.689566Z",
          "iopub.status.idle": "2023-12-27T16:41:54.453284Z",
          "shell.execute_reply.started": "2023-12-27T16:41:35.689536Z",
          "shell.execute_reply": "2023-12-27T16:41:54.452052Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56PuavIW3QHm",
        "outputId": "eee959f8-e73f-4861-d1b8-5974cd5bd583"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------------------------------------------------------------------\n",
            "INPUT PROMPT:\n",
            "\n",
            "Summarize the following conversation.\n",
            "\n",
            "### Input:\n",
            "A federal appeals court has given new life to a Holocaust survivor's claim that the University of Oklahoma is unjustly harboring a Camille Pissarro painting that the Nazis stole from her father during World War II. The 2nd U.S. Circuit Court of Appeals in Manhattan has directed a lower-court judge to consider whether the lawsuit she threw out should be transferred to Oklahoma, saying she has authority to do so. The court's order on Thursday came as the school found itself amid a racial controversy after video of fraternity students engaged in a racist chant spread across the Internet. Dr. Leone-Noelle Meyer maintained she is entitled to Pissarro's 1886 'Shepherdess Bringing in Sheep' because it belonged to her father when it was taken by the Nazis as Germany moved across France . University President David Boren ordered a fraternity house closed and expelled two of its members after reviewing clips of the chant that referenced lynching and said blacks would never be allowed in the fraternity. The school and Boren are defendants in the lawsuit brought in 2013 by 75-year-old Holocaust survivor Leone Meyer, who lives in Paris. She maintained she is entitled to Pissarro's 1886 'Shepherdess Bringing in Sheep' because it belonged to her father when it was taken by the Nazis as Germany moved across France. Her father, Raoul Mayer, died in 1970. Swiss records show Meyer's father in Paris had owned the painting. But a Swiss court ruled that the painting's post-war owners had properly established ownership and rejected her claim. Bequeathed to OU by Clara Weitzenhoffer, the wife of oil tycoon Aaron Weitzenhoffer, the school displayed it publicly for over a decade. The painting: Swiss records show Leone-Noelle Meyer's father in Paris had owned the painting 'Shepherdess Bringing in Sheep' by Camille Pissaro . Disputed item: This Monday, May 12, 2014 photo shows a display of information on the 1886 painting 'Shepherdess Bringing in Sheep' by Camille Pissarro . The Weitzenhoffers bought the painting from a New York gallery in 1956. When she died in 2000, she donated more than 30 works worth about $50 million to the University of Oklahoma. In an emailed statement Saturday, Oklahoma University spokeswoman Catherine F. Bishop said: 'The University is continuing its efforts to work with the plaintiffs to determine all the facts in this matter, some of which may still be unknown, and to seek a mutually agreeable resolution.' Last year, Boren defended Oklahoma University's ownership, saying the school does not want to keep any items it does not legitimately own but also wants to avoid a bad precedent by automatically giving away gifts it receives to anyone who claims them. Boren and the school have opposed the lawsuit on largely procedural grounds, saying the school has sovereign immunity and that Meyer was not diligent in pursuing her claim and had sued in New York rather than Oklahoma as a 'forum shopping strategy' to avoid Oklahoma's more restrictive statute of limitations. Several Oklahoma lawmakers who authored a resolution in the state Legislature seeking to force the school to turn the painting over have spoken out against the university's position. In a letter to the people of Oklahoma, Meyer has said her quest 'has nothing to do with money. It is about justice and a duty to remember.' Pierre Ciric, a lawyer for Meyer, said Saturday he welcomed 'any progress toward the resolution of our client's claim.' 'It appears that everyone involved with this case agrees that `La Bergere' was the property of my client's father prior to the Nazi occupation of France, which we have asserted since the complaint was filed,' he said. Under fire: The court's order on Thursday came as the school found itself amid a racial controversy after video showing Sigma Alpha Epsilon members singing a racist chant while traveling on a tour bus went viral .\n",
            "\n",
            "### Summary:\n",
            "\n",
            "---------------------------------------------------------------------------------------------------\n",
            "BASELINE HUMAN SUMMARY:\n",
            "The court's order after video of fraternity students at the school engaged in a racist chant spread across the Internet .\n",
            "The school and Boren are defendants in the lawsuit brought in 2013 by 75-year-old Holocaust survivor Leone Meyer, who lives in Paris .\n",
            "Meyer says she entitled to Pissarro's 1886 'Shepherdess Bringing in Sheep' because it belonged to her father when it was taken by the Nazis .\n",
            "Swiss records show Meyer's father, Raoul Meyer,  had owned the painting in Paris .\n",
            "\n",
            "---------------------------------------------------------------------------------------------------\n",
            "MODEL GENERATION - ZERO SHOT:\n",
            "\n",
            "Summarize the following conversation.\n",
            "\n",
            "### Input:\n",
            "A federal appeals court has given new life to a Holocaust survivor's claim that the University of Oklahoma is unjustly harboring a Camille Pissarro painting that the Nazis stole from her father during World War II. The 2nd U.S. Circuit Court of Appeals in Manhattan has directed a lower-court judge to consider whether the lawsuit she threw out should be transferred to Oklahoma, saying she has authority to do so. The court's order on Thursday came as the school found itself amid a racial controversy after video of fraternity students engaged in a racist chant spread across the Internet. Dr. Leone-Noelle Meyer maintained she is entitled to Pissarro's 1886 'Shepherdess Bringing in Sheep' because it belonged to her father when it was taken by the Nazis as Germany moved across France. University President David Boren ordered a fraternity house closed and expelled two of its members after reviewing clips of the chant that referenced lynching and said blacks would never be allowed in the fraternity. The school and Boren are defendants in the lawsuit brought in 2013 by 75-year-old Holocaust survivor Leone Meyer, who lives in Paris. She maintained she is entitled to Pissarro's 1886 'Shepherdess Bringing in Sheep' because it belonged to her father when it was taken by the Nazis as Germany moved across France. Her father, Raoul Mayer, died in 1970. Swiss records show Meyer's father in Paris had owned the painting. But a Swiss court ruled that the painting's post-war owners had properly established ownership and rejected her claim. Bequeathed to OU by Clara Weitzenhoffer, the wife of oil tycoon Aaron Weitzenhoffer, the school displayed it publicly for over a decade. The painting: Swiss records show Leone-Noelle Meyer's father in Paris had owned the painting 'Shepherdess Bringing in Sheep' by Camille Pissaro. Disputed item: This Monday, May 12, 2014 photo shows a display of information on the 1886 painting 'Shepherdess Bringing in Sheep' by Camille Pissarro. The Weitzenhoffers bought the painting from a New York gallery in 1956. When she died in 2000, she donated more than 30 works worth about $50 million to the University of Oklahoma. In an emailed statement Saturday, Oklahoma University spokeswoman Catherine F. Bishop said: 'The University is continuing its efforts to work with the plaintiffs to determine all the facts in this matter, some of which may still be unknown, and to seek a mutually agreeable resolution.' Last year, Boren defended Oklahoma University's ownership, saying the school does not want to keep any items it does not legitimately own but also wants to avoid a bad precedent by automatically giving away gifts it receives to anyone who claims them. Boren and the school have opposed the lawsuit on largely procedural grounds, saying the school has sovereign immunity and that Meyer was not diligent in pursuing her claim and had sued in New York rather than Oklahoma as a 'forum shopping strategy' to avoid Oklahoma's more restrictive statute of limitations. Several Oklahoma lawmakers who authored a resolution in the state Legislature seeking to force the school to turn the painting over have spoken out against the university's position. In a letter to the people of Oklahoma, Meyer has said her quest 'has nothing to do with money. It is about justice and a duty to remember.' Pierre Ciric, a lawyer for Meyer, said Saturday he welcomed 'any progress toward the resolution of our client's claim.' 'It appears that everyone involved with this case agrees that `La Bergere' was the property of my client's father prior to the Nazi occupation of France, which we have asserted since the complaint was filed,' he said. Under fire: The court's order on Thursday came as the school found itself amid a racial controversy after video showing Sigma Alpha Epsilon members singing a racist chant while traveling on a tour bus went viral.\n",
            "\n",
            "### Summary:\n",
            "\n",
            "The University of Oklahoma has been sued by a group of Holocaust survivors who say the university has been unjustly harboring a Camille Pissarro painting that the Nazis stole from her father during World War II. The 2nd U.S. Circuit Court of Appeals in Manhattan has ordered a lower-court judge to consider whether the lawsuit she threw out should be transferred to Oklahoma, saying she has authority to do so. The court's order on Thursday came as the school found itself amid a racial\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TRAINING STEP (FINE TUNING)**"
      ],
      "metadata": {
        "id": "dYzH8VS03QHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import prepare_model_for_kbit_training\n",
        "\n",
        "def print_trainable_parameters(model):\n",
        "    \"\"\"\n",
        "    Prints the number of trainable parameters in the model.\n",
        "    \"\"\"\n",
        "    trainable_params = 0\n",
        "    all_param = 0\n",
        "    for _, param in model.named_parameters():\n",
        "\n",
        "        all_param += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_params += param.numel()\n",
        "    print(\n",
        "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "model.gradient_checkpointing_enable()\n",
        "model = prepare_model_for_kbit_training(model)\n",
        "print(model)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-27T16:41:54.454570Z",
          "iopub.execute_input": "2023-12-27T16:41:54.454905Z",
          "iopub.status.idle": "2023-12-27T16:41:54.541115Z",
          "shell.execute_reply.started": "2023-12-27T16:41:54.454878Z",
          "shell.execute_reply": "2023-12-27T16:41:54.540034Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aSdPjc833QHm",
        "outputId": "ccfe71d8-a611-4db3-aabc-fef6e25f26fd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPT2LMHeadModel(\n",
            "  (transformer): GPT2Model(\n",
            "    (wte): Embedding(50257, 768)\n",
            "    (wpe): Embedding(1024, 768)\n",
            "    (drop): Dropout(p=0.1, inplace=False)\n",
            "    (h): ModuleList(\n",
            "      (0-11): 12 x GPT2Block(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): GPT2Attention(\n",
            "          (c_attn): Linear4bit(in_features=768, out_features=2304, bias=True)\n",
            "          (c_proj): Linear4bit(in_features=768, out_features=768, bias=True)\n",
            "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): GPT2MLP(\n",
            "          (c_fc): Linear4bit(in_features=768, out_features=3072, bias=True)\n",
            "          (c_proj): Linear4bit(in_features=3072, out_features=768, bias=True)\n",
            "          (act): NewGELUActivation()\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip show peft"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XH5td0zWJPHn",
        "outputId": "312539e8-a012-49ca-8202-e8c23b5f9610"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: peft\n",
            "Version: 0.9.0\n",
            "Summary: Parameter-Efficient Fine-Tuning (PEFT)\n",
            "Home-page: https://github.com/huggingface/peft\n",
            "Author: The HuggingFace team\n",
            "Author-email: sourab@huggingface.co\n",
            "License: Apache\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: accelerate, huggingface-hub, numpy, packaging, psutil, pyyaml, safetensors, torch, tqdm, transformers\n",
            "Required-by: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import LoraConfig, get_peft_model\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Define LoraConfig for your model\n",
        "lora_config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=64,\n",
        "    target_modules=[\"c_attn\", \"c_proj\", \"c_fc\"],\n",
        "    lora_dropout=0.1,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\"\n",
        ")\n",
        "model = get_peft_model(model, lora_config)\n",
        "print_trainable_parameters(model)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-27T16:41:54.542626Z",
          "iopub.execute_input": "2023-12-27T16:41:54.543076Z",
          "iopub.status.idle": "2023-12-27T16:41:54.978099Z",
          "shell.execute_reply.started": "2023-12-27T16:41:54.543034Z",
          "shell.execute_reply": "2023-12-27T16:41:54.976934Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50U_MFjE3QHm",
        "outputId": "aa81301a-3c69-4190-a80c-43cfdb7f7665"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 2359296 || all params: 84331776 || trainable%: 2.7976358519948636\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import TrainingArguments\n",
        "\n",
        "# Check if GPU is available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "OUTPUT_DIR = \"gpt2-docsum-adapter\"\n",
        "\n",
        "training_arguments = TrainingArguments(\n",
        "    per_device_train_batch_size=2 if device.type == 'cuda' else 1,  # Adjust batch size for GPU vs CPU\n",
        "    gradient_accumulation_steps=2,\n",
        "    optim=\"adamw_hf\",  # 'adamw_hf' is more general, assuming GPU setup\n",
        "    logging_steps=1,  # Log every 10 steps\n",
        "    learning_rate=1e-4,\n",
        "    fp16=True,  # Disable fp16 since it's not supported on CPU\n",
        "    max_grad_norm=0.3,\n",
        "    num_train_epochs=2,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=5,  # Changed to a reasonable integer value\n",
        "    warmup_ratio=0.05,\n",
        "    save_strategy=\"epoch\",\n",
        "    group_by_length=True,\n",
        "    output_dir=OUTPUT_DIR,\n",
        "    report_to=\"tensorboard\",\n",
        "    save_safetensors=True,\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    seed=42,\n",
        ")\n",
        "\n",
        "print(\"Training arguments set up successfully!\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-27T16:41:54.979762Z",
          "iopub.execute_input": "2023-12-27T16:41:54.980140Z",
          "iopub.status.idle": "2023-12-27T16:41:54.989521Z",
          "shell.execute_reply.started": "2023-12-27T16:41:54.980109Z",
          "shell.execute_reply": "2023-12-27T16:41:54.988301Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ELXHMZH3QHm",
        "outputId": "b4982d6a-50fc-4a47-9bad-b7a21c7afb39"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training arguments set up successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[100]['text']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "eMcLSR4s6gYq",
        "outputId": "10c47f03-06e7-4d44-e1b6-ed2812054a4f"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"### Instruction:\\nSummarize the following conversation.\\n\\n### Input:\\nBy . Alex Horlock . PUBLISHED: . 07:18 EST, 15 October 2012 . | . UPDATED: . 08:54 EST, 15 October 2012 . A manager at a homeless people’s charity helped herself to £361,000 by writing herself cheques and used the cash to renovate her house and go shopping at Marks and Spencer. Samantha Wilding, from Bristol, forged signatures to write herself cheques and used a company credit card at Marks & Spencer and to stay at a hotel. The mother-of-three stole the money when she worked for Way Ahead Housing, which merged into charity Independent People, Bristol Crown Court heard. Caught out: Samantha Wilding, pictured outside Bristol Crown Court, admitted stealing more than £350,000 from the homeless charity she worked at as a manager . The court also heard that the cost of her home renovations got out of hand and that she needed the extra money to tide her over. Wilding, 46, pleaded guilty to three counts of fraud as well as a charge of theft, spanning from 2005 to last year. Judge Carol Hagen told her: 'This was a very substantial fraud over a long period of time. It represents a gross breach of trust.' Caighli Taylor, prosecuting, said Wilding was employed as a corporate services director from 2001, dealing with finance, human resources and administration. Audacious: Wilding spent the cash on renovations to her home and trips to Marks and Spencer, Bristol Crown Court, pictured, heard . Miss Taylor said: 'She had access to bank accounts, financial systems, the company chequebook and credit card. She was a signatory to the company’s bank accounts.' When forged cheques were noticed by the company, Wilding offered to resign, the court heard. Further forged cheques materialised, including one in which Wilding forged the signature of a colleague on maternity leave. Miss Taylor said Wilding put £452.01 on the company credit card with a trip to Liverpool, Marks & Spencer and a hotel. The theft charge related to her taking £60 from a 'staff rent tin', the court heard. The long-term fraud meant the charity lost means for future investment, Miss Taylor told the court.Jason Taylor, defending, said: “Clearly, this has to be custody. 'Miss Wilding has said she needs to face the consequences. She understands she should be punished.' Theft: Ms Wilding spent some of the stolen money from the charity in the Marks and Spencer chain. File photo . Mr Taylor said his client had wanted to extend her house for £25,000, but the project escalated to £45,000. He said: 'Her intention was that money borrowed would be just to tide her over. She did not lead an extravagant lifestyle. She replaced the bathroom and they went to Spain for a week. 'Over time the money mounted up. A trail would always lead back to her because her signature was on the cheques. It took six years and she has now admitted the offences completely.' Wilding was sentenced to two years in prison last Friday.\\n\\n### Summary:\\nSamantha Wilding, 46, from Bristol, forged cheques while manager at charity Way Ahead Housing .\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from trl import SFTTrainer\n",
        "devices = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    train_dataset=train_data,\n",
        "    eval_dataset=validation_data,\n",
        "    peft_config=lora_config,\n",
        "    dataset_text_field=\"text\",\n",
        "    max_seq_length=1024,\n",
        "    tokenizer=tokenizer,\n",
        "    args=training_arguments,\n",
        ")\n",
        "\n",
        "# Start training\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-27T16:41:54.992721Z",
          "iopub.execute_input": "2023-12-27T16:41:54.993122Z",
          "iopub.status.idle": "2023-12-27T20:26:51.344620Z",
          "shell.execute_reply.started": "2023-12-27T16:41:54.993080Z",
          "shell.execute_reply": "2023-12-27T20:26:51.343660Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "0b493b465eb54645b25aec59d4d25b04",
            "eedd59e2bba6422f8adb100c808a79ba",
            "53e1910f461b4644ae25936e4131a54d",
            "490b67bb0fcd44efa6b481694fe80129",
            "b98c2132cc72489384a90d1908037b84",
            "670b0f3f82484dae9cc106ebff0816fd",
            "826a03da86c94e619df0c59bbbfe33b9",
            "275e99bb7e344a2988d4aa7c572b61c5",
            "9d62c214724b41688a970ca7f5f220be",
            "4fd33323970644998da0547c83b15987",
            "73eab8393ea640e8a50914a027247663",
            "fe701bc358534709ac4ac88c4d93b093",
            "b98969a43a04417399096d1888aeaffd",
            "a73f22793df44d6cacd2d13815a84457",
            "75a9e1b8adae4911b8070d363a017f96",
            "bd01fca21cfd4021aac7d0f18290563e",
            "6b53f83865b04b4992ea6aefbd6ee02c",
            "c8d3c0d50864430bab68ecf5c600d58a",
            "ac0a17cdfe904c57ac5cd0298ed065cf",
            "330a9a8e32fa4bdbaf00b0906dcd42ab",
            "d7475e4592ff449bb61569be3000e549",
            "dbe60b2837b34e0ba6029ba987ef98c4"
          ]
        },
        "id": "kXVG8tIp3QHm",
        "outputId": "2bc28385-e1a5-4f84-e9fd-76b6b2aa2898"
      },
      "execution_count": 17,
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0b493b465eb54645b25aec59d4d25b04",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fe701bc358534709ac4ac88c4d93b093",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='437' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [437/500 17:14 < 02:29, 0.42 it/s, Epoch 1.74/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>3.479100</td>\n",
              "      <td>3.109506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>3.684200</td>\n",
              "      <td>3.102527</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>3.334700</td>\n",
              "      <td>3.092667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>3.622600</td>\n",
              "      <td>3.083439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>3.142100</td>\n",
              "      <td>3.067725</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>3.111500</td>\n",
              "      <td>3.041409</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>3.695100</td>\n",
              "      <td>3.010642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>3.135300</td>\n",
              "      <td>2.990326</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>3.362700</td>\n",
              "      <td>2.978499</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>2.897800</td>\n",
              "      <td>2.966971</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>3.557300</td>\n",
              "      <td>2.950414</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>3.243400</td>\n",
              "      <td>2.941407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>65</td>\n",
              "      <td>3.010100</td>\n",
              "      <td>2.933530</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>3.335400</td>\n",
              "      <td>2.923241</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>3.177900</td>\n",
              "      <td>2.911434</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>3.232500</td>\n",
              "      <td>2.902836</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>85</td>\n",
              "      <td>3.241300</td>\n",
              "      <td>2.896502</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>2.756600</td>\n",
              "      <td>2.890558</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>95</td>\n",
              "      <td>3.336100</td>\n",
              "      <td>2.884325</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>2.922500</td>\n",
              "      <td>2.878918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>105</td>\n",
              "      <td>3.379900</td>\n",
              "      <td>2.874831</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>3.135200</td>\n",
              "      <td>2.871745</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>115</td>\n",
              "      <td>3.165800</td>\n",
              "      <td>2.871527</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>2.960300</td>\n",
              "      <td>2.870049</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>3.156400</td>\n",
              "      <td>2.866861</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>3.034000</td>\n",
              "      <td>2.862974</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>135</td>\n",
              "      <td>3.034200</td>\n",
              "      <td>2.859768</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>3.111000</td>\n",
              "      <td>2.859629</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>145</td>\n",
              "      <td>2.816700</td>\n",
              "      <td>2.858632</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>2.780200</td>\n",
              "      <td>2.857115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>155</td>\n",
              "      <td>3.298700</td>\n",
              "      <td>2.854147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>3.234100</td>\n",
              "      <td>2.851612</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>165</td>\n",
              "      <td>3.037700</td>\n",
              "      <td>2.851890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>3.102700</td>\n",
              "      <td>2.851567</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>175</td>\n",
              "      <td>3.046700</td>\n",
              "      <td>2.851017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>3.215400</td>\n",
              "      <td>2.849899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>185</td>\n",
              "      <td>2.780600</td>\n",
              "      <td>2.847340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>3.059100</td>\n",
              "      <td>2.845255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>195</td>\n",
              "      <td>2.961500</td>\n",
              "      <td>2.844521</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>3.034100</td>\n",
              "      <td>2.844766</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>205</td>\n",
              "      <td>3.029200</td>\n",
              "      <td>2.845145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>3.327500</td>\n",
              "      <td>2.843804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>215</td>\n",
              "      <td>3.065100</td>\n",
              "      <td>2.843845</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>3.102400</td>\n",
              "      <td>2.844244</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>225</td>\n",
              "      <td>3.113000</td>\n",
              "      <td>2.844026</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>2.915900</td>\n",
              "      <td>2.842371</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>235</td>\n",
              "      <td>2.957100</td>\n",
              "      <td>2.840562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>3.042600</td>\n",
              "      <td>2.838325</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>245</td>\n",
              "      <td>2.852700</td>\n",
              "      <td>2.837003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>2.647100</td>\n",
              "      <td>2.837443</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>255</td>\n",
              "      <td>3.259900</td>\n",
              "      <td>2.838027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>3.157000</td>\n",
              "      <td>2.838067</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>265</td>\n",
              "      <td>3.002100</td>\n",
              "      <td>2.838542</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>270</td>\n",
              "      <td>3.024500</td>\n",
              "      <td>2.838890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>275</td>\n",
              "      <td>2.703700</td>\n",
              "      <td>2.838093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>3.101900</td>\n",
              "      <td>2.836633</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>285</td>\n",
              "      <td>2.905000</td>\n",
              "      <td>2.835206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>290</td>\n",
              "      <td>2.739400</td>\n",
              "      <td>2.834654</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>295</td>\n",
              "      <td>2.931400</td>\n",
              "      <td>2.835071</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>2.484800</td>\n",
              "      <td>2.836087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>305</td>\n",
              "      <td>3.193600</td>\n",
              "      <td>2.836582</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>310</td>\n",
              "      <td>3.055200</td>\n",
              "      <td>2.836393</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>315</td>\n",
              "      <td>3.017900</td>\n",
              "      <td>2.836427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>320</td>\n",
              "      <td>2.894900</td>\n",
              "      <td>2.836194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>325</td>\n",
              "      <td>2.983200</td>\n",
              "      <td>2.835930</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>330</td>\n",
              "      <td>2.945900</td>\n",
              "      <td>2.835421</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>335</td>\n",
              "      <td>3.216800</td>\n",
              "      <td>2.834614</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>340</td>\n",
              "      <td>2.818600</td>\n",
              "      <td>2.833890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>345</td>\n",
              "      <td>3.362800</td>\n",
              "      <td>2.833076</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>2.742600</td>\n",
              "      <td>2.832516</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>355</td>\n",
              "      <td>3.329400</td>\n",
              "      <td>2.832108</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>360</td>\n",
              "      <td>2.942600</td>\n",
              "      <td>2.832052</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>365</td>\n",
              "      <td>3.049100</td>\n",
              "      <td>2.832234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>370</td>\n",
              "      <td>3.105200</td>\n",
              "      <td>2.832294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>375</td>\n",
              "      <td>3.015000</td>\n",
              "      <td>2.832104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>380</td>\n",
              "      <td>2.877400</td>\n",
              "      <td>2.832347</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>385</td>\n",
              "      <td>2.848500</td>\n",
              "      <td>2.832052</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>390</td>\n",
              "      <td>2.995800</td>\n",
              "      <td>2.831784</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>395</td>\n",
              "      <td>2.580200</td>\n",
              "      <td>2.831517</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>2.906200</td>\n",
              "      <td>2.831264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>405</td>\n",
              "      <td>3.121300</td>\n",
              "      <td>2.831184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>410</td>\n",
              "      <td>3.145200</td>\n",
              "      <td>2.831087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>415</td>\n",
              "      <td>3.044600</td>\n",
              "      <td>2.831247</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>420</td>\n",
              "      <td>3.105800</td>\n",
              "      <td>2.831204</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>425</td>\n",
              "      <td>2.900600</td>\n",
              "      <td>2.831215</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>430</td>\n",
              "      <td>2.847600</td>\n",
              "      <td>2.831168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>435</td>\n",
              "      <td>3.146800</td>\n",
              "      <td>2.830977</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [500/500 19:42, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>3.479100</td>\n",
              "      <td>3.109506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>3.684200</td>\n",
              "      <td>3.102527</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>3.334700</td>\n",
              "      <td>3.092667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>3.622600</td>\n",
              "      <td>3.083439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>3.142100</td>\n",
              "      <td>3.067725</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>3.111500</td>\n",
              "      <td>3.041409</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>3.695100</td>\n",
              "      <td>3.010642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>3.135300</td>\n",
              "      <td>2.990326</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>3.362700</td>\n",
              "      <td>2.978499</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>2.897800</td>\n",
              "      <td>2.966971</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>3.557300</td>\n",
              "      <td>2.950414</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>3.243400</td>\n",
              "      <td>2.941407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>65</td>\n",
              "      <td>3.010100</td>\n",
              "      <td>2.933530</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>3.335400</td>\n",
              "      <td>2.923241</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>3.177900</td>\n",
              "      <td>2.911434</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>3.232500</td>\n",
              "      <td>2.902836</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>85</td>\n",
              "      <td>3.241300</td>\n",
              "      <td>2.896502</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>2.756600</td>\n",
              "      <td>2.890558</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>95</td>\n",
              "      <td>3.336100</td>\n",
              "      <td>2.884325</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>2.922500</td>\n",
              "      <td>2.878918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>105</td>\n",
              "      <td>3.379900</td>\n",
              "      <td>2.874831</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>3.135200</td>\n",
              "      <td>2.871745</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>115</td>\n",
              "      <td>3.165800</td>\n",
              "      <td>2.871527</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>2.960300</td>\n",
              "      <td>2.870049</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>3.156400</td>\n",
              "      <td>2.866861</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>3.034000</td>\n",
              "      <td>2.862974</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>135</td>\n",
              "      <td>3.034200</td>\n",
              "      <td>2.859768</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>3.111000</td>\n",
              "      <td>2.859629</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>145</td>\n",
              "      <td>2.816700</td>\n",
              "      <td>2.858632</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>2.780200</td>\n",
              "      <td>2.857115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>155</td>\n",
              "      <td>3.298700</td>\n",
              "      <td>2.854147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>3.234100</td>\n",
              "      <td>2.851612</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>165</td>\n",
              "      <td>3.037700</td>\n",
              "      <td>2.851890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>3.102700</td>\n",
              "      <td>2.851567</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>175</td>\n",
              "      <td>3.046700</td>\n",
              "      <td>2.851017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>3.215400</td>\n",
              "      <td>2.849899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>185</td>\n",
              "      <td>2.780600</td>\n",
              "      <td>2.847340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>3.059100</td>\n",
              "      <td>2.845255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>195</td>\n",
              "      <td>2.961500</td>\n",
              "      <td>2.844521</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>3.034100</td>\n",
              "      <td>2.844766</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>205</td>\n",
              "      <td>3.029200</td>\n",
              "      <td>2.845145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>3.327500</td>\n",
              "      <td>2.843804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>215</td>\n",
              "      <td>3.065100</td>\n",
              "      <td>2.843845</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>3.102400</td>\n",
              "      <td>2.844244</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>225</td>\n",
              "      <td>3.113000</td>\n",
              "      <td>2.844026</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>2.915900</td>\n",
              "      <td>2.842371</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>235</td>\n",
              "      <td>2.957100</td>\n",
              "      <td>2.840562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>3.042600</td>\n",
              "      <td>2.838325</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>245</td>\n",
              "      <td>2.852700</td>\n",
              "      <td>2.837003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>2.647100</td>\n",
              "      <td>2.837443</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>255</td>\n",
              "      <td>3.259900</td>\n",
              "      <td>2.838027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>3.157000</td>\n",
              "      <td>2.838067</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>265</td>\n",
              "      <td>3.002100</td>\n",
              "      <td>2.838542</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>270</td>\n",
              "      <td>3.024500</td>\n",
              "      <td>2.838890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>275</td>\n",
              "      <td>2.703700</td>\n",
              "      <td>2.838093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>3.101900</td>\n",
              "      <td>2.836633</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>285</td>\n",
              "      <td>2.905000</td>\n",
              "      <td>2.835206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>290</td>\n",
              "      <td>2.739400</td>\n",
              "      <td>2.834654</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>295</td>\n",
              "      <td>2.931400</td>\n",
              "      <td>2.835071</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>2.484800</td>\n",
              "      <td>2.836087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>305</td>\n",
              "      <td>3.193600</td>\n",
              "      <td>2.836582</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>310</td>\n",
              "      <td>3.055200</td>\n",
              "      <td>2.836393</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>315</td>\n",
              "      <td>3.017900</td>\n",
              "      <td>2.836427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>320</td>\n",
              "      <td>2.894900</td>\n",
              "      <td>2.836194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>325</td>\n",
              "      <td>2.983200</td>\n",
              "      <td>2.835930</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>330</td>\n",
              "      <td>2.945900</td>\n",
              "      <td>2.835421</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>335</td>\n",
              "      <td>3.216800</td>\n",
              "      <td>2.834614</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>340</td>\n",
              "      <td>2.818600</td>\n",
              "      <td>2.833890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>345</td>\n",
              "      <td>3.362800</td>\n",
              "      <td>2.833076</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>2.742600</td>\n",
              "      <td>2.832516</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>355</td>\n",
              "      <td>3.329400</td>\n",
              "      <td>2.832108</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>360</td>\n",
              "      <td>2.942600</td>\n",
              "      <td>2.832052</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>365</td>\n",
              "      <td>3.049100</td>\n",
              "      <td>2.832234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>370</td>\n",
              "      <td>3.105200</td>\n",
              "      <td>2.832294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>375</td>\n",
              "      <td>3.015000</td>\n",
              "      <td>2.832104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>380</td>\n",
              "      <td>2.877400</td>\n",
              "      <td>2.832347</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>385</td>\n",
              "      <td>2.848500</td>\n",
              "      <td>2.832052</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>390</td>\n",
              "      <td>2.995800</td>\n",
              "      <td>2.831784</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>395</td>\n",
              "      <td>2.580200</td>\n",
              "      <td>2.831517</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>2.906200</td>\n",
              "      <td>2.831264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>405</td>\n",
              "      <td>3.121300</td>\n",
              "      <td>2.831184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>410</td>\n",
              "      <td>3.145200</td>\n",
              "      <td>2.831087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>415</td>\n",
              "      <td>3.044600</td>\n",
              "      <td>2.831247</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>420</td>\n",
              "      <td>3.105800</td>\n",
              "      <td>2.831204</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>425</td>\n",
              "      <td>2.900600</td>\n",
              "      <td>2.831215</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>430</td>\n",
              "      <td>2.847600</td>\n",
              "      <td>2.831168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>435</td>\n",
              "      <td>3.146800</td>\n",
              "      <td>2.830977</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>440</td>\n",
              "      <td>2.842600</td>\n",
              "      <td>2.830868</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>445</td>\n",
              "      <td>2.884500</td>\n",
              "      <td>2.830870</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>2.724700</td>\n",
              "      <td>2.830690</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>455</td>\n",
              "      <td>2.961000</td>\n",
              "      <td>2.830740</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>460</td>\n",
              "      <td>3.101000</td>\n",
              "      <td>2.830612</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>465</td>\n",
              "      <td>3.245900</td>\n",
              "      <td>2.830660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>470</td>\n",
              "      <td>2.969400</td>\n",
              "      <td>2.830555</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>475</td>\n",
              "      <td>2.871900</td>\n",
              "      <td>2.830655</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>480</td>\n",
              "      <td>2.697200</td>\n",
              "      <td>2.830656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>485</td>\n",
              "      <td>3.021100</td>\n",
              "      <td>2.830551</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>490</td>\n",
              "      <td>3.017900</td>\n",
              "      <td>2.830489</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>495</td>\n",
              "      <td>2.991500</td>\n",
              "      <td>2.830635</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>2.659400</td>\n",
              "      <td>2.830527</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=500, training_loss=3.0646606187820433, metrics={'train_runtime': 1184.2178, 'train_samples_per_second': 1.689, 'train_steps_per_second': 0.422, 'total_flos': 438982171969536.0, 'train_loss': 3.0646606187820433, 'epoch': 2.0})"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "peft_model_path=\"./peft-dialogue-summary\"\n",
        "\n",
        "trainer.model.save_pretrained(peft_model_path)\n",
        "tokenizer.save_pretrained(peft_model_path)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-27T23:37:26.107982Z",
          "iopub.execute_input": "2023-12-27T23:37:26.108415Z",
          "iopub.status.idle": "2023-12-27T23:37:26.209048Z",
          "shell.execute_reply.started": "2023-12-27T23:37:26.108383Z",
          "shell.execute_reply": "2023-12-27T23:37:26.208124Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TF5if7083QHm",
        "outputId": "1d7e213a-a965-4c21-93e1-91b45fb5c16e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./peft-dialogue-summary/tokenizer_config.json',\n",
              " './peft-dialogue-summary/special_tokens_map.json',\n",
              " './peft-dialogue-summary/vocab.json',\n",
              " './peft-dialogue-summary/merges.txt',\n",
              " './peft-dialogue-summary/added_tokens.json',\n",
              " './peft-dialogue-summary/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **INFERENCE**"
      ],
      "metadata": {
        "id": "yB-oIltJ3QHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TextStreamer\n",
        "model.config.use_cache = True\n",
        "model.eval()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-27T20:41:33.415958Z",
          "iopub.execute_input": "2023-12-27T20:41:33.416328Z",
          "iopub.status.idle": "2023-12-27T20:41:33.448446Z",
          "shell.execute_reply.started": "2023-12-27T20:41:33.416298Z",
          "shell.execute_reply": "2023-12-27T20:41:33.447619Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4W4Vtyaj3QHm",
        "outputId": "31d8ed7f-eb8a-4b6d-cfe6-eff7c5b45aee"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PeftModelForCausalLM(\n",
              "  (base_model): LoraModel(\n",
              "    (model): GPT2LMHeadModel(\n",
              "      (transformer): GPT2Model(\n",
              "        (wte): Embedding(50257, 768)\n",
              "        (wpe): Embedding(1024, 768)\n",
              "        (drop): Dropout(p=0.1, inplace=False)\n",
              "        (h): ModuleList(\n",
              "          (0-11): 12 x GPT2Block(\n",
              "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (attn): GPT2Attention(\n",
              "              (c_attn): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=768, out_features=2304, bias=True)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=768, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=2304, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (c_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=768, out_features=768, bias=True)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=768, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=768, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "              (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): GPT2MLP(\n",
              "              (c_fc): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=768, out_features=3072, bias=True)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=768, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=3072, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (c_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=3072, out_features=768, bias=True)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=768, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (act): NewGELUActivation()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"TOKEN\"] = \"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\""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-27T20:41:34.633517Z",
          "iopub.execute_input": "2023-12-27T20:41:34.634173Z",
          "iopub.status.idle": "2023-12-27T20:41:34.638735Z",
          "shell.execute_reply.started": "2023-12-27T20:41:34.634140Z",
          "shell.execute_reply": "2023-12-27T20:41:34.637577Z"
        },
        "trusted": true,
        "id": "bunt_cCN3QHm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import AutoPeftModelForCausalLM\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "peft_model_dir = \"peft-dialogue-summary\"\n",
        "\n",
        "# load base LLM model and tokenizer\n",
        "trained_model = AutoPeftModelForCausalLM.from_pretrained(\n",
        "    peft_model_dir,\n",
        "    low_cpu_mem_usage=True,\n",
        "    torch_dtype=torch.float16,\n",
        "    load_in_4bit=True,\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(peft_model_dir)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-27T23:12:06.134045Z",
          "iopub.execute_input": "2023-12-27T23:12:06.135094Z",
          "iopub.status.idle": "2023-12-27T23:12:17.455014Z",
          "shell.execute_reply.started": "2023-12-27T23:12:06.135045Z",
          "shell.execute_reply": "2023-12-27T23:12:17.453911Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IICLfU3H3QHm",
        "outputId": "d098c337-d64f-4a69-8d39-70fa85d00dae"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of GPT2LMHeadModel were not initialized from the model checkpoint at openai-community/gpt2 and are newly initialized: ['lm_head.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index = 51\n",
        "\n",
        "dialogue = train_data['article'][index][:10000]\n",
        "summary = train_data['highlights'][index]\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Summarize the following conversation.\n",
        "\n",
        "### Input:\n",
        "{dialogue}\n",
        "\n",
        "### Summary:\n",
        "\"\"\"\n",
        "\n",
        "input_ids = tokenizer(prompt, return_tensors='pt',truncation=True).input_ids.cuda()\n",
        "outputs = trained_model.generate(input_ids=input_ids, max_new_tokens=200, )\n",
        "output= tokenizer.batch_decode(outputs.detach().cpu().numpy(), skip_special_tokens=True)[0][len(prompt):]\n",
        "\n",
        "dash_line = '-'.join('' for x in range(100))\n",
        "print(dash_line)\n",
        "print(f'INPUT PROMPT:\\n{prompt}')\n",
        "print(dash_line)\n",
        "print(f'BASELINE HUMAN SUMMARY:\\n{summary}\\n')\n",
        "print(dash_line)\n",
        "print(f'TRAINED MODEL GENERATED TEXT :\\n{output}')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-27T23:32:19.786030Z",
          "iopub.execute_input": "2023-12-27T23:32:19.787030Z",
          "iopub.status.idle": "2023-12-27T23:32:39.833407Z",
          "shell.execute_reply.started": "2023-12-27T23:32:19.786990Z",
          "shell.execute_reply": "2023-12-27T23:32:39.832415Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j93U2gM13QHn",
        "outputId": "03d27aab-14a0-4d8c-fa4a-56d8eede2064"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------------------------------------------------------------------\n",
            "INPUT PROMPT:\n",
            "\n",
            "Summarize the following conversation.\n",
            "\n",
            "### Input:\n",
            "You might expect polar bears, the Artic Circle's apex predators, to be dab hands at dancing on ice. But as this specimen in Svalbard shows, even after thousands of years of evolutionary adaptation, some still suffer from two-left feet on the frozen ocean. Heinrich Eggenfellner, a 49-year-old videographer from Norway, said: 'I have encountered polar bears many times every year since I live up here and am used to them. 'This episode, however, was extraordinary.' Born slippy: A polar walks across thin sea ice in Svalbard, Norway, where it was caught on camera looking very unsteady on its feet as it made its way across the slippery surface . Spreading its weight: The polar bear does its best not to collapse through the fragile ice by spreading out . In its element: The beast finally gave up and pushed a hole in the ice to dive into the freezing water . Mr Eggenfellner and his friend Svein Wik spent hours in Norway's northernmost territory hunting for a polar bear to film and photograph, then hours more waiting for the slumbering beast to wake up. It was time well spent. The patient duo were treated to a farcical display of slipping and sliding across the frozen sea, with their subject falling flat on its face at least once. 'Maybe we waited 3-4 hours before the bear woke up and came out onto thinner and thinner ice,' Mr Wik told Caters News Agency. 'At one point, it spread out on all four legs to prevent falling thorough the ice until finally the bear gave up, pushed through the ice and started to swim. 'He dived for a few seconds and showed up again, looking up and then started to shake of the water.' Proud: Polar bears are the Arctic Circle's apex predators and have adapted to the habitat over millennia . Evolution: Regarded as marine mammals because of the many months they spend at sea, polar bears have nevertheless adapted large, flat paws to distribute their bulk as they pad across thin ice . Brains: However this beast seems to have realised that big feet are not enough to stop it smashing through the thin ice and is trying to spread its weight to lessen the pressure beneath it . Weighty: Polar bears can weigh up to 1,100lbs, more than enough to smash through thin layers of frozen sea . Taking a dip: The polar bear pictured just after deciding it was better off taking a swim in the freezing sea . Regarded as marine mammals because of the many months they spend at sea, polar bears have nevertheless adapted large, flat paws to distribute their bulk as they pad across thin ice. They can weigh up to 1,100lbs, more than enough to smash through layers of frozen sea that would easily hold a man. Mr Wik added: 'It is difficult to explain my feelings in situations like this. I think the Polar bear is one of the most charismatic animals in the world. 'It was a rare and very interesting situation to watch everything and this was, without doubt, the ultimate wilderness experience for me.' Stunning: Photographer Svein Wik and videographer Heinrich Eggenfellner spent hours trying to find a polar bear to document in the stark frozen landscape of Svalbard, the Norwegian Arctic territory .\n",
            "\n",
            "### Summary:\n",
            "\n",
            "---------------------------------------------------------------------------------------------------\n",
            "BASELINE HUMAN SUMMARY:\n",
            "Polar bears have evolved special large, flat paws for walking on sea ice .\n",
            "But this specimen from Svalbard nevertheless struggled with its footing .\n",
            "The Arctic killer ventured off the thick ice that can support his weight .\n",
            "\n",
            "---------------------------------------------------------------------------------------------------\n",
            "TRAINED MODEL GENERATED TEXT :\n",
            "ear has been spotted in Svalbard, Norway, where it was caught on camera looking very unsteady on its feet as it made its way across the icy surface\n",
            "The polar bear has been spotted in Svalbard, Norway, where it was caught on camera looking very unsteady on its feet as it made its way across the icy surface\n",
            "The polar bear has been spotted in Svalbard, Norway, where it was caught on camera looking very unsteady on its feet as it made its way across the icy surface\n",
            "The polar bear has been spotted in Svalbard, Norway, where it was caught on camera looking very unsteady on its feet as it made its way across the icy surface\n",
            "The polar bear has been spotted in Svalbard, Norway, where it was caught on camera looking very unsteady on its feet as it made its way across the icy surface\n",
            "The polar bear has been spotted in Svalbard, Norway, where it\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hONs1fBe3QHn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}